# ðŸ¤– LLM Experiments

A collection of Google Colab notebooks exploring cutting-edge large language models (LLMs) â€” from quantization techniques to vision-capable models.  
Run any notebook directly in your browser, no local setup needed.

---

## ðŸ“› Badges

[![Open in Colab](https://img.shields.io/badge/Open%20in-Colab-orange?logo=googlecolab)](https://colab.research.google.com)
![Python](https://img.shields.io/badge/Python-3.10+-blue?logo=python)
![License](https://img.shields.io/badge/License-MIT-green)

---

## ðŸš€ Colab Notebooks

| Notebook | Description | Launch |
|----------|-------------|--------|
| **Quantize SeaLLM 7B Chat with ExLlamaV2** | Quantize and run the SeaLLM 7B chat model efficiently using ExLlamaV2. | [![Open in Colab](https://img.shields.io/badge/Colab-Open-orange?logo=googlecolab)](https://colab.research.google.com/drive/17CIVVM3SZq8K-J_X7mKZgjMYHuORaws7?usp=drive_link) |
| **Run LLaMA 3.2 Vision Model with Ollama** | Deploy and run the LLaMA 3.2 Vision model locally via Ollama. | [![Open in Colab](https://img.shields.io/badge/Colab-Open-orange?logo=googlecolab)](https://colab.research.google.com/drive/1R6iLjc2LZyoIrRISKy9mNavO8UxjqGaZ?usp=drive_link) |

---

## ðŸ“¸ Previews (Optional)

| SeaLLM Quantization | LLaMA Vision |
|---|---|
| <img src="assets/seallm_demo.png" width="400"/> | <img src="assets/llama_vision_demo.png" width="400"/> |

---

## âš¡ Getting Started

1. Click **Open in Colab** to launch the notebook.
2. Make sure you're signed into a Google account.
3. Run each cell in order and follow the on-screen instructions.
